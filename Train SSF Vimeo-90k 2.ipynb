{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  6 15:29:03 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A40          On   | 00000000:D8:00.0 Off |                    0 |\r\n",
      "|  0%   33C    P8    30W / 300W |      0MiB / 46068MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.utils.spectral_norm as spectralnorm\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#from models import *\n",
    "from utils import *\n",
    "from helper import *\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else cpu)\n",
    "from vimeo90k import Vimeo90kDataset, VideoFolder_diffusion\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 of 802\n",
      "batch 100 of 802\n",
      "batch 200 of 802\n",
      "batch 300 of 802\n",
      "batch 400 of 802\n",
      "batch 500 of 802\n",
      "batch 600 of 802\n",
      "batch 700 of 802\n",
      "batch 800 of 802\n",
      "| EPOCH: 0 | MSE LOSS: 0.002188011072576046 | AR LOSS: -71.71698760986328 | TIME: 52.83122721115748 min|\n",
      "saving models...\n",
      "batch 0 of 802\n",
      "batch 100 of 802\n",
      "batch 200 of 802\n",
      "batch 300 of 802\n",
      "batch 400 of 802\n",
      "batch 500 of 802\n",
      "batch 600 of 802\n",
      "batch 700 of 802\n",
      "batch 800 of 802\n",
      "| EPOCH: 1 | MSE LOSS: 0.0020114595536142588 | AR LOSS: -1168.339111328125 | TIME: 103.36968898773193 min|\n",
      "saving models...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "device = torch.device('cuda' if torch.cuda.is_available else cpu)\n",
    "from models import Discriminator_v3\n",
    "from ssf_model import ScaleSpaceFlow\n",
    "import time\n",
    "\n",
    "LAMBDA_GP = 0\n",
    "LAMBDA_MSE = 1\n",
    "EPOCHS = 2\n",
    "LAMBDA_AR = 0\n",
    "\n",
    "model_name = f'AR_FT_2_epochs_MSE'\n",
    "\n",
    "def load_ssf_model(model, pre_path):\n",
    "    model.motion_encoder.load_state_dict(torch.load(pre_path+'/m_enc.pth'))\n",
    "    model.motion_decoder.load_state_dict(torch.load(pre_path+'/m_dec.pth'))\n",
    "    model.P_encoder.load_state_dict(torch.load(pre_path+'/p_enc.pth'))\n",
    "    model.res_encoder.load_state_dict(torch.load(pre_path+'/r_enc.pth'))\n",
    "    model.res_decoder.load_state_dict(torch.load(pre_path+'/r_dec.pth'))\n",
    "    return model\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0),  1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake[:],\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.RandomCrop(256)])\n",
    "\n",
    "train_dataset = VideoFolder_diffusion(\n",
    "        \"./data/vimeo-90k/vimeo_triplet/\",\n",
    "        rnd_interval=False,\n",
    "        rnd_temp_order=False,\n",
    "        split=\"train\",\n",
    "        transform=train_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        pin_memory=True)\n",
    "\n",
    "discriminator_AR = Discriminator_v3(ch=256, out_ch=6).to(device)\n",
    "discriminator_AR.load_state_dict(torch.load(f'./saved_models/vimeo-90k/AR_0.08/discriminator_AR.pth'))\n",
    "ssf = ScaleSpaceFlow().to(device)\n",
    "ssf = load_ssf_model(ssf, f'./saved_models/vimeo-90k/AR_0.08/')\n",
    "opt_AR = torch.optim.Adam(discriminator_AR.parameters(), lr=1e-5)\n",
    "opt_ssf = torch.optim.Adam(ssf.parameters(), lr=5e-5)\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "a = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    mse_list = []\n",
    "    AR_list = []\n",
    "    mse_epoch = 0\n",
    "    AR_epoch = 0\n",
    "    ssf.train()\n",
    "    discriminator_AR.train()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if i%100 == 0:\n",
    "            print(f'batch {i} of {len(train_dataloader)}')\n",
    "        opt_AR.zero_grad()\n",
    "        opt_ssf.zero_grad()\n",
    "        \n",
    "        x1 = 2*(data[:,0,...]-0.5)\n",
    "        x2 = 2*(data[:,1,...]-0.5)\n",
    "        x1_hat = 2*(data[:,3,...]-0.5)\n",
    "        x1=x1.to(device)\n",
    "        x2=x2.to(device)\n",
    "        x1_hat = x1_hat.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x2_hat = ssf([x1_hat, x2])\n",
    "        \n",
    "        #change code\n",
    "        real_vid = torch.cat((x1_hat, x2), dim = 1)\n",
    "        fake_vid = torch.cat((x1_hat, x2_hat), dim =1)\n",
    "        fake_validity = discriminator_AR(fake_vid.detach())\n",
    "        real_validity = discriminator_AR(real_vid)\n",
    "        \n",
    "        #gradient_penalty = compute_gradient_penalty(discriminator, real_vid.data, fake_vid.data)\n",
    "        errAR =  -torch.mean(real_validity) + torch.mean(fake_validity) #+ LAMBDA_GP * gradient_penalty\n",
    "        errAR.backward()\n",
    "        opt_AR.step()\n",
    "        AR_list.append(errAR.item())    \n",
    "\n",
    "\n",
    "        # ssf optim\n",
    "        x1 = x1.detach()\n",
    "        x2 = x2.detach()\n",
    "        x1_hat = x1_hat.detach()\n",
    "        x2_hat = ssf([x1_hat, x2])\n",
    "        fake_vid = torch.cat((x1_hat, x2_hat), dim =1)\n",
    "        fake_validity = discriminator_AR(fake_vid.detach())        \n",
    "        \n",
    "        errAR_ = -torch.mean(fake_validity)\n",
    "        x2_hat = ssf([x1_hat, x2])\n",
    "        mse_loss = mse(x2_hat, x2)\n",
    "        loss = LAMBDA_MSE * mse_loss + LAMBDA_AR*errAR_\n",
    "        mse_list.append(mse_loss.item())\n",
    "        loss.backward()\n",
    "        opt_ssf.step()\n",
    "            \n",
    "    if epoch % 1 == 0:\n",
    "        mse_epoch = torch.Tensor(mse_list).mean().item()\n",
    "    AR_epoch = torch.Tensor(AR_list).mean().item()\n",
    "\n",
    "    b = time.time()\n",
    "    run_time = (b-a)/60\n",
    "    print(f'| EPOCH: {epoch} | MSE LOSS: {mse_epoch} | AR LOSS: {AR_epoch} | TIME: {run_time} min|')\n",
    "    #if epoch % 1 == 0:\n",
    "    print('saving models...')\n",
    "    os.makedirs(f'./saved_models/vimeo-90k/{model_name}', exist_ok=True)\n",
    "    ssf.eval()\n",
    "    discriminator_AR.eval()\n",
    "    torch.save(discriminator_AR.state_dict(), f\"./saved_models/vimeo-90k/{model_name}/discriminator_AR.pth\")\n",
    "    torch.save(ssf.motion_encoder.state_dict(), f'./saved_models/vimeo-90k/{model_name}/m_enc.pth')\n",
    "    torch.save(ssf.motion_decoder.state_dict(), f'./saved_models/vimeo-90k/{model_name}/m_dec.pth')\n",
    "    torch.save(ssf.P_encoder.state_dict(), f'./saved_models/vimeo-90k/{model_name}/p_enc.pth')\n",
    "    torch.save(ssf.res_encoder.state_dict(), f'./saved_models/vimeo-90k/{model_name}/r_enc.pth')\n",
    "    torch.save(ssf.res_decoder.state_dict(), f'./saved_models/vimeo-90k/{model_name}/r_dec.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
