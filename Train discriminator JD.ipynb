{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  7 16:18:52 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A40          On   | 00000000:86:00.0 Off |                    0 |\r\n",
      "|  0%   26C    P8    29W / 300W |      0MiB / 46068MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.utils.spectral_norm as spectralnorm\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#from models import *\n",
    "from utils import *\n",
    "from helper import *\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else cpu)\n",
    "from vimeo90k import Vimeo90kDataset, VideoFolder_diffusion\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 of 802\n",
      "batch 100 of 802\n",
      "batch 200 of 802\n",
      "batch 300 of 802\n",
      "batch 400 of 802\n",
      "batch 500 of 802\n",
      "batch 600 of 802\n",
      "batch 700 of 802\n",
      "batch 800 of 802\n",
      "| EPOCH: 0 | JD PLF: -2314.036376953125 TIME: 43.86436767975489 min|\n",
      "saving models...\n",
      "batch 0 of 802\n",
      "batch 100 of 802\n",
      "batch 200 of 802\n",
      "batch 300 of 802\n",
      "batch 400 of 802\n",
      "batch 500 of 802\n",
      "batch 600 of 802\n",
      "batch 700 of 802\n",
      "batch 800 of 802\n",
      "| EPOCH: 1 | JD PLF: -13154.9951171875 TIME: 82.26859695514044 min|\n",
      "saving models...\n",
      "batch 0 of 802\n",
      "batch 100 of 802\n",
      "batch 200 of 802\n",
      "batch 300 of 802\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "device = torch.device('cuda' if torch.cuda.is_available else cpu)\n",
    "from models import Discriminator_v3\n",
    "from ssf_model import ScaleSpaceFlow\n",
    "import time\n",
    "\n",
    "LAMBDA_GP = 50\n",
    "LAMBDA_MSE = 1\n",
    "EPOCHS = 50\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0),  1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake[:],\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.RandomCrop(256)])\n",
    "\n",
    "train_dataset = VideoFolder_diffusion(\n",
    "        \"./data/vimeo-90k/vimeo_triplet/\",\n",
    "        rnd_interval=False,\n",
    "        rnd_temp_order=False,\n",
    "        split=\"train\",\n",
    "        transform=train_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        pin_memory=True)\n",
    "\n",
    "discriminator_JD = Discriminator_v3(ch=256, out_ch=6).to(device)\n",
    "#discriminator_JD.load_state_dict(torch.load('./saved_models/vimeo-90k/discriminator_JD.pth'))\n",
    "opt_JD = torch.optim.Adam(discriminator_JD.parameters(), lr=5e-6)\n",
    "\n",
    "a = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    JD_list = []\n",
    "    JD_epoch = 0\n",
    "    discriminator_JD.train()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if i%100 == 0:\n",
    "            print(f'batch {i} of {len(train_dataloader)}')\n",
    "        opt_JD.zero_grad()        \n",
    "        x1 = 2*(data[:,0,...]-0.5)\n",
    "        x2 = 2*(data[:,1,...]-0.5)\n",
    "        x1_hat = 2*(data[:,3,...]-0.5)\n",
    "        x1=x1.to(device)\n",
    "        x2=x2.to(device)\n",
    "        x1_hat = x1_hat.to(device)\n",
    "        \n",
    "        x1_hat = x1_hat.to(device)\n",
    "        #change code\n",
    "        real_vid = torch.cat((x1, x2), dim = 1)\n",
    "        fake_vid = torch.cat((x1_hat, x2), dim = 1)\n",
    "        real_vid = real_vid[:32]\n",
    "        fake_vid = fake_vid[32:]\n",
    "        fake_validity = discriminator_JD(fake_vid.detach())\n",
    "        real_validity = discriminator_JD(real_vid)\n",
    "        \n",
    "        #gradient_penalty = compute_gradient_penalty(discriminator, real_vid.data, fake_vid.data)\n",
    "        errJD =  -torch.mean(real_validity) + torch.mean(fake_validity) #+ LAMBDA_GP * gradient_penalty\n",
    "        errJD.backward()\n",
    "        opt_JD.step()\n",
    "        JD_list.append(errJD.item())        \n",
    "            \n",
    "    JD_epoch = torch.Tensor(JD_list).mean().item()\n",
    "    b = time.time()\n",
    "    run_time = (b-a)/60\n",
    "    print(f'| EPOCH: {epoch} | JD PLF: {JD_epoch} TIME: {run_time} min|')\n",
    "          \n",
    "    if epoch % 1 == 0:\n",
    "        print('saving models...')\n",
    "        discriminator_JD.eval()\n",
    "        torch.save(discriminator_JD.state_dict(), os.path.join(\"./saved_models/vimeo-90k/discriminator_JD.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.Tensor(AR_list).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
